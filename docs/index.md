# STEP: A Unified Spiking Transformer Evaluation Platform

<p align="center">
  <img src="STEP.jpg" alt="STEP overview" style="width:40%; max-width:600px; min-width:200px;" />
</p>

<p align="center">
  <img src="https://img.shields.io/badge/python-3.8%20|%203.9%20|%203.10-blue" alt="Python"/>
  <img src="https://img.shields.io/badge/framework-BrainCog-blue" alt="BrainCog"/>
  <img src="https://img.shields.io/badge/version-1.1.0-green" alt="Version"/>
</p>

STEP is built on top of [BrainCog](https://github.com/BrainCog-X/Brain-Cog) and provides a unified pipeline for classification, segmentation, and object detection tasks using spiking transformer models. It ensures fair, reproducible benchmarking while remaining easy to extend with new models or tasks, and supports multiple backends including BrainCog, SpikingJelly, and BrainPy.

---

## üöÄ Quick Start
This is the official [STEP](https://github.com/Fancyssc/STEP) tutorial. To help you easily use and understand the content of the Benchmark framework as well as get hands-on experience with it, we will mainly provide you with tutorials on installation, model construction, and configuration.


## üìùCitation

```angular2html
@misc{shen2025stepunifiedspikingtransformer,
      title={STEP: A Unified Spiking Transformer Evaluation Platform for Fair and Reproducible Benchmarking}, 
      author={Sicheng Shen and Dongcheng Zhao and Linghao Feng and Zeyang Yue and Jindong Li and Tenglong Li and Guobin Shen and Yi Zeng},
      year={2025},
      eprint={2505.11151},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/2505.11151}, 
}
```